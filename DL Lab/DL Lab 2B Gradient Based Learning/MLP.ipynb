{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n"
      ],
      "metadata": {
        "id": "4-HaoBNJNVA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[0],[0],[1]])\n"
      ],
      "metadata": {
        "id": "VHRFFnTlNPAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(0)\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "qDdPUbZWNKx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1"
      ],
      "metadata": {
        "id": "Clxzqxy-NZFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random weights and bias initialization\n",
        "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)"
      ],
      "metadata": {
        "id": "wT648FqoNg7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZqTc77eLLsN",
        "outputId": "c8310632-29c8-4b6e-f282-8eb6ea550e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in multiply\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\thidden_layer_activation += hidden_bias\n",
        "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "\t\n",
        "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLuZN5NVNpl4",
        "outputId": "904b55b7-4a18-49e5-f58a-e73f6882fc46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final hidden weights: [nan nan] [nan nan]\n",
            "Final hidden bias: [nan nan]\n",
            "Final output weights: [nan] [nan]\n",
            "Final output bias: [nan]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [nan] [nan] [nan] [nan]\n"
          ]
        }
      ]
    }
  ]
}