{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1keQhVD7Op-C",
        "outputId": "4212d8eb-4826-4408-9d1b-c159f18cfab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial output weights: [0.23880611] [0.00781346]\n",
            "Initial output biases: [0.71582676]\n",
            "Final output weights: [-2.89938747e-16] [-2.85658302e-16]\n",
            "Final output bias: [0.5]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.5] [0.5] [0.5] [0.5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "#np.random.seed(0)\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
        "\n",
        "#Random weights and bias initialization\n",
        "# hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "# hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "output_weights = np.random.uniform(size=(inputLayerNeurons ,outputLayerNeurons))\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "# print(\"Initial hidden weights: \",end='')\n",
        "# print(*hidden_weights)\n",
        "# print(\"Initial hidden biases: \",end='')\n",
        "# print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "\n",
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\t# hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\t# hidden_layer_activation += hidden_bias\n",
        "\t# hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(inputs,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = output_layer_activation\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error \n",
        "\t# error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\t# d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += inputs.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\t# hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\t# hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n",
        "# print(\"Final hidden weights: \",end='')\n",
        "# print(*hidden_weights)\n",
        "# print(\"Final hidden bias: \",end='')\n",
        "# print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "#np.random.seed(0)\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
        "\n",
        "#Random weights and bias initialization\n",
        "# hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "# hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "output_weights = np.random.uniform(size=(inputLayerNeurons ,outputLayerNeurons))\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "# print(\"Initial hidden weights: \",end='')\n",
        "# print(*hidden_weights)\n",
        "# print(\"Initial hidden biases: \",end='')\n",
        "# print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "\n",
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\t# hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\t# hidden_layer_activation += hidden_bias\n",
        "\t# hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(inputs,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error * sigmoid_derivative(error)\n",
        "\t# error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\t# d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += inputs.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\t# hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\t# hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n",
        "# print(\"Final hidden weights: \",end='')\n",
        "# print(*hidden_weights)\n",
        "# print(\"Final hidden bias: \",end='')\n",
        "# print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjFxNNXoZJFQ",
        "outputId": "267a2193-de6f-47f3-970d-8755f292c713"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial output weights: [0.86429042] [0.45860657]\n",
            "Initial output biases: [0.63022434]\n",
            "Final output weights: [2000.73154224] [2000.33053839]\n",
            "Final output bias: [3999.81527011]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [1.] [1.] [1.] [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np \n",
        "#np.random.seed(0)\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
        "\n",
        "#Random weights and bias initialization\n",
        "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "\n",
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\thidden_layer_activation += hidden_bias\n",
        "\thidden_layer_output = (hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = (output_layer_activation)\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error\n",
        "\t\n",
        "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\td_hidden_layer = error_hidden_layer \n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq28IufRbbmd",
        "outputId": "e59c2d3a-36eb-4a0c-a548-c3af3d6f196e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [0.34970855 0.25020394] [0.63569328 0.39650139]\n",
            "Initial hidden biases: [0.05145235 0.63360415]\n",
            "Initial output weights: [0.35165106] [0.52529215]\n",
            "Initial output biases: [0.18178625]\n",
            "Final hidden weights: [0.30553023 0.09453758] [0.55922971 0.17303762]\n",
            "Final hidden bias: [0.02108772 0.64254591]\n",
            "Final output weights: [-0.10747629] [0.34734606]\n",
            "Final output bias: [0.27908064]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.5] [0.5] [0.5] [0.5]\n"
          ]
        }
      ]
    }
  ]
}